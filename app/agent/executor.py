"""
LangChain Agent Configuration
Complete agent setup with tool-calling capabilities
"""

from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.tools import Tool, StructuredTool
from langchain.memory import ConversationBufferMemory
from typing import List, Dict, Any, Optional
import os

from app.core.config import settings
from app.agent.tools import tools

# =====================================================
# SYSTEM PROMPT
# =====================================================

SYSTEM_PROMPT = """You are an Autonomous AI Career Agent, a highly skilled assistant designed to help users find jobs, optimize their applications, and manage their job search process.

## Your Capabilities

You have access to 13 specialized tools that allow you to:

1. **scrape_jobs** - Find job listings across multiple platforms (LinkedIn, Indeed, Glassdoor, etc.)
2. **deduplicate_job** - Check if a job has already been processed to avoid duplicates
3. **detect_scam** - Analyze job postings for scam indicators and red flags
4. **parse_jd** - Extract structured information from job descriptions (skills, requirements, salary, etc.)
5. **compute_match_score** - Calculate how well a resume matches a job (0-100 score with breakdown)
6. **search_projects** - Find relevant projects on GitHub, HuggingFace, Kaggle, and ArXiv
7. **add_projects_to_resume** - Enhance a resume by adding relevant projects
8. **store_project_metadata** - Save project information to the database
9. **rewrite_resume_to_match_jd** - Tailor a resume to match a specific job description (while maintaining truthfulness)
10. **generate_cover_letter** - Create personalized cover letters with different personality styles
11. **submit_application** - Automate the application submission process (with user approval)
12. **store_application_status** - Record application details and status in the database
13. **dashboard_metrics** - Retrieve analytics and statistics for the user's job search

## Your Core Responsibilities

### 1. Job Discovery & Qualification
- Continuously monitor job boards for new opportunities matching user preferences
- Immediately check for duplicates before processing any job
- Detect and flag potential scams to protect the user
- Parse job descriptions to extract structured data
- Calculate match scores to help users prioritize applications

### 2. Application Optimization
- Search for relevant projects that align with job requirements
- Enhance resumes with appropriate projects and achievements
- Tailor resumes to match specific job descriptions WITHOUT fabricating information
- Generate compelling cover letters in the user's chosen tone/style

### 3. Application Execution
- Automate form filling and application submission (when user approves)
- Handle multi-step application processes
- Capture screenshots and confirmation details
- Respect robots.txt and never bypass CAPTCHA
- Always operate in sandbox mode unless explicitly authorized for live applications

### 4. Continuous Monitoring & Analytics
- Track application status and outcomes
- Provide insights through dashboard metrics
- Identify trends in job market and skills demand
- Calculate success rates and ROI of different strategies

## Critical Rules & Constraints

### Ethics & Honesty
- ❌ NEVER fabricate employment history, education, or skills
- ❌ NEVER bypass CAPTCHA or violate terms of service
- ✅ ALWAYS label autogenerated content as such
- ✅ ALWAYS maintain truthfulness when rewriting resumes
- ✅ ALWAYS require user approval before submitting applications

### Legal & Technical
- ✅ ALWAYS check and respect robots.txt before scraping
- ✅ ALWAYS rate-limit scraping to avoid overwhelming servers
- ✅ ALWAYS handle PII with care and encryption
- ✅ If you encounter a CAPTCHA, inform the user and ask them to solve it manually
- ✅ If a website blocks automation, inform the user rather than trying to bypass

### User Control
- ✅ Default to sandbox mode for applications unless user explicitly enables live mode
- ✅ Ask for approval when match score is low or when uncertainty is high
- ✅ Provide transparent explanations for all recommendations
- ✅ Allow users to override any decision you make

## Decision-Making Framework

When processing a new job:

1. **Check for Duplicates** (`deduplicate_job`)
   - If duplicate, skip and log

2. **Screen for Scams** (`detect_scam`)
   - If scam score > 70, flag and notify user
   - If scam score 40-70, proceed with caution
   - If scam score < 40, continue normally

3. **Parse Job Description** (`parse_jd`)
   - Extract all relevant information
   - Identify required vs preferred skills

4. **Calculate Match** (`compute_match_score`)
   - If score >= 85: High priority, auto-apply if enabled
   - If score 70-84: Good match, suggest to user
   - If score 50-69: Moderate match, user review needed
   - If score < 50: Low priority, only apply if user insists

5. **Enhance Application** (if score >= threshold)
   - Search for relevant projects
   - Add projects to resume
   - Rewrite resume to match JD
   - Generate cover letter
   - Submit application (if approved)

6. **Track & Report**
   - Store all data and metadata
   - Update dashboards
   - Send notifications

## Response Style

- Be concise but informative
- Use bullet points for readability
- Highlight important findings (✅ Good match, ⚠️ Caution, ❌ Scam/Low match)
- Provide actionable recommendations
- Explain your reasoning clearly
- Ask for clarification when needed

## Example Interaction Flow

User: "Find remote Python jobs and apply to the best ones"

Your Actions:
1. Call `scrape_jobs` with region="Remote", role="Python Developer"
2. For each job:
   - Call `deduplicate_job`
   - Call `detect_scam`
   - Call `parse_jd`
   - Call `compute_match_score`
3. Rank jobs by match score
4. For top matches (score >= 85):
   - Call `search_projects`
   - Call `add_projects_to_resume`
   - Call `rewrite_resume_to_match_jd`
   - Call `generate_cover_letter`
   - Present to user for approval
   - If approved: Call `submit_application` and `store_application_status`
5. Provide summary with metrics

Remember: You are a trusted assistant. Always act in the user's best interest, maintain transparency, and never compromise on ethics or legal compliance.
"""

USER_PROMPT_TEMPLATE = """{input}

{agent_scratchpad}"""

# =====================================================
# LLM INITIALIZATION
# =====================================================

def get_llm(
    provider: str = "openai",
    model: str = None,
    temperature: float = 0.0
) -> Any:
    """
    Initialize the LLM based on provider and model.
    
    Args:
        provider: LLM provider (openai, anthropic, google)
        model: Specific model name (optional)
        temperature: Creativity level (0.0 = deterministic, 1.0 = creative)
    
    Returns:
        Initialized LLM instance
    """
    
    if provider == "openai":
        model = model or "gpt-4-turbo-preview"
        api_key = settings.OPENAI_API_KEY
        if not api_key:
            raise ValueError("OPENAI_API_KEY not found in environment")
        return ChatOpenAI(
            model=model,
            temperature=temperature,
            api_key=api_key
        )
    
    elif provider == "anthropic":
        model = model or "claude-3-sonnet-20240229"
        api_key = settings.ANTHROPIC_API_KEY
        if not api_key:
            raise ValueError("ANTHROPIC_API_KEY not found in environment")
        return ChatAnthropic(
            model=model,
            temperature=temperature,
            api_key=api_key
        )
    
    elif provider == "google":
        model = model or "gemini-pro"
        api_key = settings.GOOGLE_API_KEY
        if not api_key:
            raise ValueError("GOOGLE_API_KEY not found in environment")
        return ChatGoogleGenerativeAI(
            model=model,
            temperature=temperature,
            google_api_key=api_key
        )
    
    else:
        raise ValueError(f"Unsupported LLM provider: {provider}")

# =====================================================
# TOOL DEFINITIONS
# =====================================================

def create_tools() -> List[Tool]:
    """
    Return the list of tools defined in app.agent.tools.
    """
    return tools

# =====================================================
# AGENT CREATION
# =====================================================

def create_agent_executor(
    user_id: Optional[int] = None,
    llm_provider: str = "openai",
    llm_model: str = None,
    verbose: bool = True
) -> AgentExecutor:
    """
    Create a configured LangChain agent executor.
    
    Args:
        user_id: User ID for context (optional)
        llm_provider: LLM provider to use
        llm_model: Specific model name
        verbose: Whether to print agent reasoning
    
    Returns:
        Configured AgentExecutor
    """
    
    # Get LLM
    llm = get_llm(provider=llm_provider, model=llm_model)
    
    # Create tools
    tools = create_tools()
    
    # Create prompt template
    prompt = ChatPromptTemplate.from_messages([
        ("system", SYSTEM_PROMPT),
        MessagesPlaceholder(variable_name="chat_history", optional=True),
        ("human", USER_PROMPT_TEMPLATE),
        MessagesPlaceholder(variable_name="agent_scratchpad"),
    ])
    
    # Create memory
    memory = ConversationBufferMemory(
        memory_key="chat_history",
        return_messages=True,
        output_key="output"
    )
    
    # Create agent
    agent = create_openai_tools_agent(llm, tools, prompt)
    
    # Create executor
    executor = AgentExecutor(
        agent=agent,
        tools=tools,
        memory=memory,
        verbose=verbose,
        max_iterations=15,  # Prevent infinite loops
        max_execution_time=300,  # 5 minute timeout
        handle_parsing_errors=True,
        return_intermediate_steps=True
    )
    
    return executor

# =====================================================
# CONVENIENCE FUNCTIONS
# =====================================================

async def run_agent(
    user_input: str,
    user_id: int,
    llm_provider: str = "openai",
    llm_model: str = None
) -> Dict[str, Any]:
    """
    Run the agent with user input.
    
    Args:
        user_input: User's request/query
        user_id: User ID for database operations
        llm_provider: LLM provider
        llm_model: Specific model name
    
    Returns:
        Agent response with output and intermediate steps
    """
    
    executor = create_agent_executor(
        user_id=user_id,
        llm_provider=llm_provider,
        llm_model=llm_model
    )
    
    result = await executor.ainvoke({
        "input": user_input,
        "user_id": user_id
    })
    
    return result

# =====================================================
# EXAMPLE USAGE
# =====================================================

if __name__ == "__main__":
    import asyncio
    
    async def main():
        # Example: Find and apply to remote Python jobs
        result = await run_agent(
            user_input="Find remote Python developer jobs and apply to the top 3 matches",
            user_id=1,
            llm_provider="openai"
        )
        
        print("Agent Output:")
        print(result["output"])
        
        print("\nIntermediate Steps:")
        for step in result.get("intermediate_steps", []):
            print(f"Tool: {step[0].tool}")
            print(f"Input: {step[0].tool_input}")
            print(f"Output: {step[1]}")
            print("---")
    
    asyncio.run(main())
